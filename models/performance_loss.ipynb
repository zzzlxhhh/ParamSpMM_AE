{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_calculator(dim, CF, warp_size=32):\n",
    "    t_norm = min(dim, CF * warp_size)\n",
    "    t_residue = dim % (warp_size * CF)\n",
    "    # must be a multiple of CF * warp_size\n",
    "    if t_residue == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return t_norm - t_residue\n",
    "    \n",
    "def dynamic_CF_prompter(dim, CF_set=None, warp_size=32):\n",
    "    if CF_set == None:\n",
    "        CF_set = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    CF_set = CF_set[: math.ceil(dim / 32)]\n",
    "    valid_CF_set = []\n",
    "\n",
    "    for CF in CF_set:\n",
    "        gap = gap_calculator(dim, CF, warp_size)\n",
    "        print(\"dim({})->CF:{} gap:{}\".format(dim, CF, gap))\n",
    "        if gap < 32:\n",
    "            valid_CF_set.append(CF)\n",
    "    CF_set = valid_CF_set\n",
    "    return CF_set\n",
    "\n",
    "def rnd(dim, length):\n",
    "    options = len(dynamic_CF_prompter(dim))*2*2*2\n",
    "    rnd_pre = []\n",
    "    for i in range(length):\n",
    "        rnd_pre.append(np.random.randint(0, options))\n",
    "    return np.array(rnd_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mtxfeature(data, mask=None):\n",
    "    \"\"\"Get the matrix feature\"\"\"\n",
    "    # print(data.columns)\n",
    "    feature = data.drop([\"mtx_name\", \"OP_SpMM\"], axis=1)\n",
    "    np_feature = feature.values\n",
    "    # print(np_feature.shape)\n",
    "    return np_feature\n",
    "\n",
    "\n",
    "def _get_label(data, mask=None):\n",
    "    \"\"\"Get the label of the data\"\"\"\n",
    "    label = data[\"OP_SpMM\"]\n",
    "    np_label = label.values\n",
    "    return np_label\n",
    "\n",
    "\n",
    "def _get_feature_names(data, mask=None):\n",
    "    \"\"\"feature name\"\"\"\n",
    "    np_fnames = data.columns[1:-1].values\n",
    "    return np_fnames\n",
    "\n",
    "\n",
    "def _get_target_names(data, mask=None):\n",
    "    \"\"\"SpMM method name\"\"\"\n",
    "    tnames = data.iloc[0].values\n",
    "    return tnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "\n",
    "\n",
    "def load_mtx(csv_path=\"../ParamSpMM-log/\", mask=None, dim=16):\n",
    "    # random load 20% data for test\n",
    "    train_data_csv = pd.read_csv(csv_path + \"dim\" + str(dim) + \"_OP_SpMM.csv\")\n",
    "    bench_data_csv = pd.read_csv(csv_path + \"dim\" + str(dim) + \".csv\")\n",
    "\n",
    "    if mask is not None:\n",
    "        train_data_csv = train_data_csv[mask]\n",
    "        bench_data_csv = bench_data_csv[mask]\n",
    "    mtx = Bunch()\n",
    "    mtx.feature = _get_mtxfeature(train_data_csv)\n",
    "    mtx.label = _get_label(train_data_csv)\n",
    "    mtx.fnames = _get_feature_names(train_data_csv)\n",
    "    mtx.tnames = _get_target_names(bench_data_csv)\n",
    "    # mtx.num = num\n",
    "    # mtx = mtx.data[random_mask]\n",
    "    return mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def performance_loss(rnd_tree, csv_path, dim):\n",
    "    data = np.ones((202, 1))\n",
    "    data_label = np.arange(202)\n",
    "    # get test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data, data_label, test_size=0.2, random_state=17\n",
    "    )\n",
    "    mask = np.ones(len(data_label), dtype=bool)\n",
    "    mask[y_test] = False\n",
    "    mask = ~mask\n",
    "\n",
    "    mtx_data = load_mtx(csv_path=csv_path, dim=dim, mask=mask)\n",
    "    tp = pd.read_csv(csv_path + \"dim\" + str(dim) + \".csv\")[mask]\n",
    "    predict = rnd_tree.predict(mtx_data.feature)\n",
    "    rnd_pre = rnd(dim, len(predict)) \n",
    "    # cal the performance loss\n",
    "    lable = mtx_data.label # true label\n",
    "    mask = predict != lable\n",
    "    # optimal performance\n",
    "    op_tp = pd.DataFrame(tp.max(axis=1, numeric_only=True))\n",
    "    # optimal performance of wrong predict\n",
    "    mask_op = op_tp.values[mask]\n",
    "    error_num = mask.sum()\n",
    "    mask_tp = tp.values[mask]\n",
    "    mask_predict = predict[mask]\n",
    "    predict_tp = mask_tp[np.arange(error_num), mask_predict].reshape(-1, 1)\n",
    "    loss = (mask_op - predict_tp) / mask_op\n",
    "    #  rnd performance\n",
    "    rnd_mask = rnd_pre!=lable\n",
    "    rnd_mask_op = op_tp.values[rnd_mask]\n",
    "    rnd_error_num = rnd_mask.sum()\n",
    "    rnd_mask_tp = tp.values[rnd_mask]\n",
    "    rnd_predict = rnd_pre[rnd_mask]\n",
    "    rnd_predict_tp = rnd_mask_tp[np.arange(rnd_error_num), rnd_predict].reshape(-1, 1)\n",
    "    rnd_loss = (rnd_mask_op - rnd_predict_tp) / rnd_mask_op\n",
    "    \n",
    "    # test data size\n",
    "    test_size = lable.shape[0]\n",
    "    loss = loss.sum() / test_size\n",
    "    print(\"dim{} Wrong number{} in {}\".format(dim, error_num, test_size))\n",
    "    print(\"Average normalized performance: \", 1 - loss)\n",
    "    \n",
    "    # rnd loss\n",
    "    rnd_loss = rnd_loss.sum() / test_size\n",
    "    print(\"rnd dim{} Wrong number{} in {}\".format(dim, rnd_error_num, test_size))\n",
    "    print(\"Average normalized performance of random: \", 1 - rnd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import math\n",
    "\n",
    "\n",
    "def eval_performance_loss(dim, csv_path=\"./\"):\n",
    "    if dim % 32 == 0:\n",
    "        approx_dim = dim\n",
    "    else:\n",
    "        approx_dim = (math.ceil(dim / 32) * 2 - 1) * 16\n",
    "    pickle_path = \"./rnd_tree_\" + str(approx_dim) + \".pkl\"\n",
    "    rnd_tree = pickle.load(open(pickle_path, \"rb\"))\n",
    "    performance_loss(rnd_tree, csv_path, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_performance_loss(8, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(16, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(24, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(32, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(40, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(48, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(56, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(64, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(72, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(80, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(88, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(96, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(104, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(112, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(120, csv_path=\"../ParamSpMM-log/\")\n",
    "eval_performance_loss(128, csv_path=\"../ParamSpMM-log/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
