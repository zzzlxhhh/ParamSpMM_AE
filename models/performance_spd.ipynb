{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "def _get_mtxfeature(data):\n",
    "    '''Get the matrix feature '''\n",
    "    # print(data.columns)\n",
    "    feature = data.drop(['mtx_name', 'OP_SpMM'], axis=1)\n",
    "    np_feature = feature.values\n",
    "    # print(np_feature.shape)\n",
    "    return np_feature\n",
    "\n",
    "\n",
    "def _get_label(data):\n",
    "    '''Get the label of the data'''\n",
    "    label = data['OP_SpMM']\n",
    "    np_label = label.values\n",
    "    return np_label\n",
    "\n",
    "\n",
    "def _get_feature_names(data):\n",
    "    '''feature name'''\n",
    "    np_fnames = data.columns[1:-1].values\n",
    "    return np_fnames\n",
    "\n",
    "\n",
    "def _get_target_names(data):\n",
    "    '''SpMM method name'''\n",
    "    tnames = data.iloc[0].values\n",
    "    return tnames\n",
    "\n",
    "def load_mtx(csv_path=\"../ParamSpMM-log/\", mask=None, dim=16):\n",
    "    train_data_csv = pd.read_csv(csv_path + \"dim\" + str(dim) + \"_OP_SpMM.csv\")\n",
    "    bench_data_csv = pd.read_csv(csv_path + \"dim\" + str(dim) + \".csv\")\n",
    "    if mask is not None:\n",
    "        train_data_csv = train_data_csv[mask]\n",
    "        bench_data_csv = bench_data_csv[mask]\n",
    "    mtx = Bunch()\n",
    "    mtx.feature = _get_mtxfeature(train_data_csv)\n",
    "    mtx.label = _get_label(train_data_csv)\n",
    "    mtx.fnames = _get_feature_names(train_data_csv)\n",
    "    mtx.tnames = _get_target_names(bench_data_csv)\n",
    "    return mtx\n",
    "\n",
    "# speedup of ParamSpMM(with SpMM-decider) and baseline libraries over cusparse\n",
    "def performance_spd(rnd_tree, dim):\n",
    "    mtx_data = load_mtx(dim=dim)\n",
    "    tp = pd.read_csv(\"../ParamSpMM-log/dim\" + str(dim) + \".csv\")\n",
    "    predict = rnd_tree.predict(mtx_data.feature)\n",
    "    all_predict_tp = tp.values[np.arange(predict.shape[0]), predict].reshape(-1, 1)\n",
    "    # cal the performance loss\n",
    "    lable = mtx_data.label\n",
    "    mask = predict != lable\n",
    "    # optimal performance\n",
    "    op_tp = pd.DataFrame(tp.max(axis=1, numeric_only=True))\n",
    "    # optimal performance of wrong predict\n",
    "    mask_op = op_tp.values[mask]\n",
    "    error_num = mask.sum()\n",
    "    mask_tp = tp.values[mask]\n",
    "    mask_predict = predict[mask]\n",
    "    predict_tp = mask_tp[np.arange(error_num), mask_predict].reshape(-1, 1)\n",
    "    loss = (mask_op - predict_tp) / mask_op\n",
    "    # test data size\n",
    "    test_size = lable.shape[0] * 0.2\n",
    "    loss = loss.sum() / test_size\n",
    "    # print(\"Wrong number{} in {}\", error_num, test_size)\n",
    "    # print(\"Loss: \", loss)\n",
    "    # read baseline throughput of cusparse and gespmm\n",
    "    baseline = pd.read_csv(\"../ParamSpMM-log/dim\" + str(dim) + \"_baseline.csv\")\n",
    "    # cusparse_woreorder = pd.read_csv(\n",
    "    #     \"../ParamSpMM-log/ablation_study/wo_reorder/dim\" + str(dim) + \"_baseline.csv\"\n",
    "    # )\n",
    "    # read GNNA-SpMM throughput\n",
    "    gnna_op = pd.read_csv(\"../ParamSpMM-log/baseline_SpMM/GNNASpMM_op.csv\")\n",
    "    DASpMM = pd.read_csv(\"../ParamSpMM-log/baseline_SpMM/DASpMM.csv\")\n",
    "    # cal speedup\n",
    "    speedup = {}\n",
    "    # speedup[\"cusparse_wor\"] = cusparse_woreorder[\"cusparse\"] / baseline[\"cusparse\"]\n",
    "    speedup[\"gespmm\"] = baseline[\"gespmm\"] / baseline[\"cusparse\"]\n",
    "    speedup[\"GNNASpMM_op\"] = gnna_op[str(dim)] / baseline[\"cusparse\"]\n",
    "    speedup[\"DASpMM\"] = DASpMM[str(dim)] / baseline[\"cusparse\"]\n",
    "    speedup[\"ParamSpMM\"] = all_predict_tp[:, 0] / baseline[\"cusparse\"]\n",
    "    \n",
    "    # Print average speedup  \n",
    "    # print(\"Average Speedup of ParamSpMM (with SpMM-decider) and baseline libraries over cusparse:\")  \n",
    "    # print(\"GESpMM: \", pd.DataFrame(speedup[\"gespmm\"]).mean().values[0])  \n",
    "    # print(\"GNNASpMM: \", pd.DataFrame(speedup[\"GNNASpMM_op\"]).mean().values[0])  \n",
    "    # print(\"DASpMM: \", pd.DataFrame(speedup[\"DASpMM\"]).mean().values[0])  \n",
    "    # print(\"ParamSpMM: \", pd.DataFrame(speedup[\"ParamSpMM\"]).mean().values[0])  \n",
    "    \n",
    "    # Print speedup of ParamSpMM over baselines  \n",
    "    print(\"Speedup of ParamSpMM over baselines:\")  \n",
    "    print(\"CuSPARSE: \", pd.DataFrame(speedup[\"ParamSpMM\"]).values.mean())\n",
    "    print(\"GESpMM: \", (pd.DataFrame(speedup[\"ParamSpMM\"]).values / pd.DataFrame(speedup[\"gespmm\"]).values).mean())  \n",
    "    print(\"GNNASpMM: \", (pd.DataFrame(speedup[\"ParamSpMM\"]).values / pd.DataFrame(speedup[\"GNNASpMM_op\"]).values).mean())  \n",
    "    print(\"DASpMM: \", (pd.DataFrame(speedup[\"ParamSpMM\"]).values / pd.DataFrame(speedup[\"DASpMM\"]).values).mean())  \n",
    "    \n",
    "    pd.DataFrame(speedup).to_csv(\n",
    "        \"../ParamSpMM-log/spd/ParamSpMM\" + str(dim) + \"_speedup.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_list = [16,32,48,64,80,96,112,128,144,160,176,192,208,224,240,256] #16,32,48,64,80,96,112,128,,240,256\n",
    "for dim in dim_list:\n",
    "    rnd_tree = pd.read_pickle(\"./rnd_tree_\" + str(dim) + \".pkl\")\n",
    "    print(\"dim: \", dim)\n",
    "    performance_spd(rnd_tree, dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
